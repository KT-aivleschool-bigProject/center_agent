"""
RAG ê¸°ë°˜ LangGraph Agent
ë¬¸ì„œë¥¼ ë²¡í„° DBë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ RAG ë°©ì‹ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import (
    TextLoader,
    PyPDFLoader,
    DirectoryLoader,
    UnstructuredWordDocumentLoader
)
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from typing_extensions import Annotated, TypedDict


class RAGState(TypedDict):
    """RAG Agentì˜ ìƒíƒœ ì •ì˜"""
    question: str
    retrieved_docs: List[Document]
    answer: str
    error: Optional[str]
    metadata: Dict[str, Any]


class RAGAgent:
    """RAG ê¸°ë°˜ LangGraph Agent"""
    
    def __init__(self):
        self.name = "RAG Agent"
        self.embeddings = None
        self.vectorstore = None
        self.llm = None
        self.retrieval_qa = None
        self.graph = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        # ë¬¸ì„œ ì €ì¥ ê²½ë¡œ
        self.docs_path = Path("data/docs")
        self.vector_db_path = Path("data/vector_db")
        
        # ì´ˆê¸°í™”
        self._initialize_components()
        self._setup_graph()
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œëŠ” ë‚˜ì¤‘ì— ë¡œë”© (ë¹„ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ë³„ë„ í˜¸ì¶œ í•„ìš”)
        self._documents_loaded = False
    
    def _initialize_components(self):
        """LangChain êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”"""
        try:
            # OpenAI API í‚¤ í™•ì¸
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                print("âš ï¸  RAG Agent: OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            # LLM ì´ˆê¸°í™”
            self.llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.3,
                api_key=api_key
            )
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            self.embeddings = OpenAIEmbeddings(api_key=api_key)
            
            # ë²¡í„° ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ìƒì„±
            self.vector_db_path.mkdir(parents=True, exist_ok=True)
            
            print("âœ… RAG Agent êµ¬ì„± ìš”ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ RAG Agent ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    def _setup_graph(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ì •"""
        # ìƒíƒœ ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(RAGState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("entry", self._entry_node)
        workflow.add_node("retrieve_docs", self._retrieve_docs_node)
        workflow.add_node("generate_answer", self._generate_answer_node)
        workflow.add_node("output", self._output_node)
        
        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("entry")
        workflow.add_edge("entry", "retrieve_docs")
        workflow.add_edge("retrieve_docs", "generate_answer")
        workflow.add_edge("generate_answer", "output")
        workflow.add_edge("output", END)
        
        # ê·¸ë˜í”„ ì»´íŒŒì¼
        self.graph = workflow.compile()
    
    async def _load_test_documents(self):
        """í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ë¡œë”©"""
        try:
            # ë¬¸ì„œ ë””ë ‰í† ë¦¬ ìƒì„±
            self.docs_path.mkdir(parents=True, exist_ok=True)
            
            # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš°)
            test_doc1_path = self.docs_path / "project_overview.txt"
            test_doc2_path = self.docs_path / "api_documentation.txt"
            
            if not test_doc1_path.exists():
                with open(test_doc1_path, "w", encoding="utf-8") as f:
                    f.write("""
í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ê¸°ë°˜ì˜ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
1. Center Agent - ì¤‘ì•™ ê´€ë¦¬ ì—ì´ì „íŠ¸
2. RAG Agent - ë¬¸ì„œ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
3. Code Agent - ì½”ë“œ ë¦¬ë·° ë° ë¶„ì„
4. Document Agent - ë¬¸ì„œ ì‘ì„± ë° ê´€ë¦¬
5. Schedule Agent - ì¼ì • ê´€ë¦¬

ê¸°ìˆ  ìŠ¤íƒ:
- FastAPI (ë°±ì—”ë“œ ì„œë²„)
- React (í”„ë¡ íŠ¸ì—”ë“œ)
- LangChain (AI ì²´ì¸)
- LangGraph (ì›Œí¬í”Œë¡œìš°)
- OpenAI GPT-4o (ì–¸ì–´ ëª¨ë¸)
- ChromaDB (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)

í”„ë¡œì íŠ¸ ëª©í‘œ:
ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì „ë¬¸ ì—ì´ì „íŠ¸ì—ê²Œ ë¼ìš°íŒ…í•˜ê³ ,
ê° ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œ êµ¬ì¶•.
                    """)
            
            if not test_doc2_path.exists():
                with open(test_doc2_path, "w", encoding="utf-8") as f:
                    f.write("""
API ë¬¸ì„œ

1. ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
GET / - ì„œë²„ ìƒíƒœ í™•ì¸
GET /health - í—¬ìŠ¤ ì²´í¬

2. AI ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
POST /ai/process - ë©”ì‹œì§€ ì²˜ë¦¬ (ìë™ ì—ì´ì „íŠ¸ ì„ íƒ)
POST /ai/agents/{agent_type} - íŠ¹ì • ì—ì´ì „íŠ¸ í˜¸ì¶œ

3. ìš”ì²­/ì‘ë‹µ í˜•ì‹

ChatMessage:
- message: str (í•„ìˆ˜)
- user_id: str (ì„ íƒ)

ChatResponse:
- response: str
- agents_used: List[str]
- processing_time: float

4. ì—ì´ì „íŠ¸ íƒ€ì…
- manager: ê´€ë¦¬ì ì—ì´ì „íŠ¸
- code: ì½”ë“œ ë¶„ì„ ì—ì´ì „íŠ¸
- document: ë¬¸ì„œ ê´€ë¦¬ ì—ì´ì „íŠ¸
- schedule: ì¼ì • ê´€ë¦¬ ì—ì´ì „íŠ¸
- rag: ë¬¸ì„œ ê²€ìƒ‰ ì—ì´ì „íŠ¸

5. ì—ëŸ¬ ì²˜ë¦¬
- 400: ì˜ëª»ëœ ìš”ì²­
- 404: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸
- 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜

6. ì¸ì¦
í˜„ì¬ ë²„ì „ì—ì„œëŠ” ì¸ì¦ì´ êµ¬í˜„ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
í–¥í›„ JWT í† í° ê¸°ë°˜ ì¸ì¦ì„ ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤.
                    """)
            
            # ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°í™”
            await self._load_and_vectorize_documents()
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë”© ì˜¤ë¥˜: {e}")
    
    async def _load_and_vectorize_documents(self):
        """ë¬¸ì„œë¥¼ ë¡œë”©í•˜ê³  ë²¡í„°í™”í•˜ì—¬ ì €ì¥"""
        try:
            if not self.embeddings:
                print("âš ï¸  ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            documents = []
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì§ì ‘ ë¡œë”©
            for txt_file in self.docs_path.glob("*.txt"):
                try:
                    with open(txt_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        doc = Document(
                            page_content=content,
                            metadata={"source": str(txt_file)}
                        )
                        documents.append(doc)
                        print(f"âœ… ë¡œë”© ì™„ë£Œ: {txt_file.name}")
                except Exception as e:
                    print(f"âŒ {txt_file.name} ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # PDF íŒŒì¼ ë¡œë”©
            for pdf_file in self.docs_path.glob("*.pdf"):
                try:
                    loader = PyPDFLoader(str(pdf_file))
                    docs = loader.load()
                    documents.extend(docs)
                    print(f"âœ… PDF ë¡œë”© ì™„ë£Œ: {pdf_file.name}")
                except Exception as e:
                    print(f"âŒ {pdf_file.name} ë¡œë”© ì‹¤íŒ¨: {e}")
            
            # DOCX íŒŒì¼ ë¡œë”©
            for docx_file in self.docs_path.glob("*.docx"):
                try:
                    loader = UnstructuredWordDocumentLoader(str(docx_file))
                    docs = loader.load()
                    documents.extend(docs)
                    print(f"âœ… DOCX ë¡œë”© ì™„ë£Œ: {docx_file.name}")
                except Exception as e:
                    print(f"âŒ {docx_file.name} ë¡œë”© ì‹¤íŒ¨: {e}")
            
            if documents:
                # ë¬¸ì„œ ë¶„í• 
                texts = self.text_splitter.split_documents(documents)
                print(f"ğŸ“ {len(documents)}ê°œ ë¬¸ì„œë¥¼ {len(texts)}ê°œ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
                
                # ë²¡í„° ì €ì¥ì†Œ ìƒì„±/ì—…ë°ì´íŠ¸
                if self.vectorstore is None:
                    self.vectorstore = Chroma.from_documents(
                        documents=texts,
                        embedding=self.embeddings,
                        persist_directory=str(self.vector_db_path)
                    )
                    print("âœ… ìƒˆë¡œìš´ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                else:
                    self.vectorstore.add_documents(texts)
                    print("âœ… ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œì— ë¬¸ì„œë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
                
                # RetrievalQA ì²´ì¸ ì„¤ì •
                self._setup_retrieval_qa()
                
                print(f"ğŸ¯ ë²¡í„°í™” ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ, {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì²­í¬")
            else:
                print("âš ï¸  ë¡œë”©í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ë²¡í„°í™” ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def _setup_retrieval_qa(self):
        """RetrievalQA ì²´ì¸ ì„¤ì •"""
        if not self.vectorstore or not self.llm:
            return
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        prompt_template = """
ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ AIì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì£¼ë¡œ í™œìš©í•˜ë˜, í•„ìš”ì‹œ ì¼ë°˜ì ì¸ ì§€ì‹ë„ í•¨ê»˜ í™œìš©í•˜ì„¸ìš”.
2. ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
3. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…ì‹œí•˜ì„¸ìš”.
4. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€:
"""
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        self.retrieval_qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 4}
            ),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )
    
    async def _entry_node(self, state: RAGState) -> RAGState:
        """ì§„ì…ì : ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬"""
        print(f"ğŸ” RAG Agent: ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘ - {state['question']}")
        
        # ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ ë¶„ê¸°ì  (í–¥í›„ code_agent í¬ì›Œë”©ìš©)
        question_lower = state["question"].lower()
        code_keywords = ["ì½”ë“œ", "êµ¬í˜„", "ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "í•¨ìˆ˜", "í´ë˜ìŠ¤", "ë²„ê·¸"]
        
        if any(keyword in question_lower for keyword in code_keywords):
            state["metadata"] = {
                "potential_code_question": True,
                "forward_to_code_agent": False  # í˜„ì¬ëŠ” ë¹„í™œì„±í™”, í–¥í›„ í™•ì¥ì‹œ Trueë¡œ ë³€ê²½
            }
            print("ğŸ’¡ ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ê°ì§€ë¨ (í–¥í›„ code_agent í¬ì›Œë”© ê³ ë ¤)")
        else:
            state["metadata"] = {"potential_code_question": False}
        
        return state
    
    async def _retrieve_docs_node(self, state: RAGState) -> RAGState:
        """ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ"""
        try:
            if not self.vectorstore:
                state["error"] = "ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë¨¼ì € ë¡œë”©í•´ì£¼ì„¸ìš”."
                print("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ ë¡œë”©ì„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")
                await self._load_test_documents()  # ë¬¸ì„œ ì¬ë¡œë”© ì‹œë„
                if not self.vectorstore:
                    return state
            
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 4}
            )
            
            docs = retriever.get_relevant_documents(state["question"])
            state["retrieved_docs"] = docs
            
            print(f"ğŸ“š {len(docs)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.")
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ì„ ê²½ìš° ëŒ€ì²´ ì‘ë‹µ ì¤€ë¹„
            if not docs:
                state["error"] = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                print("âš ï¸  ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            state["error"] = f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return state
    
    async def _generate_answer_node(self, state: RAGState) -> RAGState:
        """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
        try:
            if state.get("error"):
                # ì˜¤ë¥˜ê°€ ìˆì§€ë§Œ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ì‘ë‹µ ìƒì„±
                if "ë²¡í„° ì €ì¥ì†Œ" in state["error"] or "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in state["error"]:
                    state["answer"] = f"""ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë¬¸ì„œ ì €ì¥ì†Œì— ê´€ë ¨ ì •ë³´ê°€ ì—†ì–´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì§ˆë¬¸: {state["question"]}

ëŒ€ì‹  ì¼ë°˜ì ì¸ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
â€¢ í”„ë¡œì íŠ¸ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
â€¢ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë‹¤ë¥¸ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
â€¢ ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì€ 'code' ì—ì´ì „íŠ¸ì—ê²Œ, ë¬¸ì„œ ì‘ì„±ì€ 'document' ì—ì´ì „íŠ¸ì—ê²Œ ë¬¸ì˜í•´ë³´ì„¸ìš”."""
                    state["error"] = None  # ì—ëŸ¬ë¥¼ í´ë¦¬ì–´í•˜ì—¬ ì •ìƒ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
                    print("ğŸ“ ëŒ€ì²´ ì‘ë‹µì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                    return state
                else:
                    return state
            
            if not self.retrieval_qa:
                state["error"] = "RetrievalQA ì²´ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                return state
            
            # RAG ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            result = self.retrieval_qa({"query": state["question"]})
            state["answer"] = result["result"]
            
            # ì†ŒìŠ¤ ë¬¸ì„œ ì •ë³´ ì¶”ê°€
            if result.get("source_documents"):
                state["metadata"]["source_count"] = len(result["source_documents"])
                state["answer"] += f"\n\nğŸ“‹ ì°¸ì¡°í•œ ë¬¸ì„œ: {len(result['source_documents'])}ê°œ"
            
            print("âœ… RAG ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            state["error"] = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        
        return state
    
    async def _output_node(self, state: RAGState) -> RAGState:
        """ì¶œë ¥ ë…¸ë“œ"""
        if state.get("error"):
            state["answer"] = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {state['error']}"
        
        print("ğŸ“¤ RAG Agent ì²˜ë¦¬ ì™„ë£Œ")
        return state
    
    async def process(self, message: str) -> str:
        """ë©”ì‹œì§€ ì²˜ë¦¬ (FastAPI í†µí•©ìš©)"""
        try:
            # ì²« ë²ˆì§¸ ìš”ì²­ì‹œ ë¬¸ì„œ ë¡œë”©
            if not self._documents_loaded:
                await self._load_test_documents()
                self._documents_loaded = True
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = RAGState(
                question=message,
                retrieved_docs=[],
                answer="",
                error=None,
                metadata={}
            )
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            if self.graph:
                result = await self.graph.ainvoke(initial_state)
                return result["answer"]
            else:
                return "RAG Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        except Exception as e:
            return f"RAG Agent ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def add_documents(self, file_paths: List[str]) -> str:
        """ìƒˆ ë¬¸ì„œ ì¶”ê°€"""
        try:
            documents = []
            for file_path in file_paths:
                path = Path(file_path)
                if path.suffix == ".txt":
                    loader = TextLoader(str(path))
                elif path.suffix == ".pdf":
                    loader = PyPDFLoader(str(path))
                elif path.suffix == ".docx":
                    loader = UnstructuredWordDocumentLoader(str(path))
                else:
                    continue
                
                docs = loader.load()
                documents.extend(docs)
            
            if documents and self.vectorstore:
                texts = self.text_splitter.split_documents(documents)
                self.vectorstore.add_documents(texts)
                return f"{len(documents)}ê°œ ë¬¸ì„œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                return "ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
        
        except Exception as e:
            return f"ë¬¸ì„œ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}"
